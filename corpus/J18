J18 0010  1    #6.4. THE PRIMARY DECOMPOSITION THEOREM#
J18 0010  6    We are trying to study a linear operator T on the
J18 0020  6    finite-dimensional space V, by decomposing T into
J18 0030  5    a direct sum of operators which are in some sense elementary.
J18 0040  3    We can do this through the characteristic values and
J18 0050  2    vectors of T in certain special cases, i.e., when
J18 0050 11    the minimal polynomial for T factors over the scalar
J18 0060  9    field F into a product of distinct monic polynomials
J18 0070  8    of degree 1. What can we do with the general T? If
J18 0080  8    we try to study T using characteristic values, we
J18 0090  4    are confronted with two problems. First, T may not
J18 0100  4    have a single characteristic value; this is really
J18 0110  1    a deficiency in the scalar field, namely, that it is
J18 0110 11    not algebraically closed. Second, even if the characteristic
J18 0120  7    polynomial factors completely over F into a product
J18 0130  6    of polynomials of degree 1, there may not be enough
J18 0140  5    characteristic vectors for T to span the space V;
J18 0150  3    this is clearly a deficiency in T. The second situation
J18 0160  2    is illustrated by the operator T on **f (F any field)
J18 0170  3    represented in the standard basis by **f. The characteristic
J18 0180  1    polynomial for A is **f and this is plainly also the
J18 0180 12    minimal polynomial for A (or for T). Thus T is not
J18 0200  1    diagonalizable. One sees that this happens because
J18 0200  8    the null space of **f has dimension 1 only. On the
J18 0210  8    other hand, the null space of **f and the null space
J18 0220  4    of **f together span V, the former being the subspace
J18 0230  2    spanned by **f and the latter the subspace spanned
J18 0230 11    by **f and **f.
J18 0240  2       This will be more or less our general method for
J18 0240 12    the second problem. If (remember this is an assumption)
J18 0250  8    the minimal polynomial for T decomposes **f where
J18 0260  6    **f are distinct elements of F, then we shall show
J18 0270  5    that the space V is the direct sum of the null spaces
J18 0280  5    of **f. The diagonalizable operator is the special
J18 0290  1    case of this in which **f for each i. The theorem
J18 0290 12    which we prove is more general than what we have described,
J18 0300  9    since it works with the primary decomposition of the
J18 0310  5    minimal polynomial, whether or not the primes which
J18 0320  2    enter are all of first degree. The reader will find
J18 0320 12    it helpful to think of the special case when the primes
J18 0330 10    are of degree 1, and even more particularly, to think
J18 0340  6    of the proof of Theorem 10, a special case of this
J18 0350  4    theorem.
J18 0350  5    #THEOREM 12. (PRIMARY DECOMPOSITION THEOREM).#
J18 0360  1    Let T be a linear operator on the finite-dimensional
J18 0370  1    vector space V over the field F. Let p be the minimal
J18 0380  2    polynomial for T, **f where the **f are distinct irreducible
J18 0390  1    monic polynomials over F and the **f are positive
J18 0390 10    integers. Let **f be the null space of **f. Then (a)
J18 0400 11    **f (b) each **f is invariant under T (c) if **f is
J18 0410  9    the operator induced on **f by T, then the minimal
J18 0420  4    polynomial for **f is **f.
J18 0430  1    _PROOF._
J18 0430  1       The idea of the proof is this. If the direct-sum
J18 0430 12    decomposition (a) is valid, how can we get hold of
J18 0440 10    the projections **f associated with the decomposition?
J18 0450  3    The projection **f will be the identity on **f and
J18 0460  2    zero on the other **f. We shall find a polynomial **f
J18 0460 13    such that **f is the identity on **f and is zero on
J18 0470 11    the other **f, and so that **f, etc.
J18 0480  3       For each i, let **f. Since **f are distinct prime
J18 0490  2    polynomials, the polynomials **f are relatively prime
J18 0490  9    (Theorem 8, Chapter 4). Thus there are polynomials
J18 0500  8    **f such that **f. Note also that if **f, then **f
J18 0510  7    is divisible by the polynomial p, because **f contains
J18 0520  4    each **f as a factor. We shall show that the polynomials
J18 0530  1    **f behave in the manner described in the first paragraph
J18 0530 11    of the proof.
J18 0540  3       Let **f. Since **f and p divides **f for **f, we
J18 0550  2    have **f. Thus the **f are projections which correspond
J18 0550 11    to some direct-sum decomposition of the space V. We
J18 0560  9    wish to show that the range of **f is exactly the subspace
J18 0570  9    **f. It is clear that each vector in the range of **f
J18 0580  7    is in **f for if |a is in the range of **f, then **f
J18 0590  4    and so **f because **f is divisible by the minimal
J18 0590 14    polynomial p. Conversely, suppose that |a is in the
J18 0600  9    null space of **f. If **f, then **f is divisible by
J18 0610 10    **f and so **f, i.e., **f. But then it is immediate
J18 0620  7    that **f, i.e., that |a is in the range of **f. This
J18 0630  6    completes the proof of statement (a).
J18 0640  1       It is certainly clear that the subspaces **f are
J18 0640 10    invariant under T. If **f is the operator induced
J18 0650  7    on **f by T, then evidently **f, because by definition
J18 0660  5    **f is 0 on the subspace **f. This shows that the minimal
J18 0670  4    polynomial for **f divides **f. Conversely, let g
J18 0680  2    be any polynomial such that **f. Then **f. Thus **f
J18 0680 12    is divisible by the minimal polynomial p of T, i.e.,
J18 0690  9    **f divides **f. It is easily seen that **f divides
J18 0700 10    g. Hence the minimal polynomial for **f is **f.
J18 0710  7    #COROLLARY.#
J18 0710  8    If **f are the projections associated with the primary
J18 0720  6    decomposition of T, then each **f is a polynomial
J18 0730  6    in T, and accordingly if a linear operator U commutes
J18 0740  4    with T then U commutes with each of the **f i.e.,
J18 0750  6    each subspace **f is invariant under U.
J18 0760  1       In the notation of the proof of Theorem 12, let
J18 0760 11    us take a look at the special case in which the minimal
J18 0770 10    polynomial for T is a product of first-degree polynomials,
J18 0780  8    i.e., the case in which each **f is of the form **f.
J18 0790  8    Now the range of **f is the null space **f of **f.
J18 0800  4    Let us put **f. By Theorem 10, D is a diagonalizable
J18 0810  1    operator which we shall call the diagonalizable part
J18 0820  1    of T. Let us look at the operator **f. Now **f **f
J18 0830 11    so **f. The reader should be familiar enough with projections
J18 0840  7    by now so that he sees that **f and in general that
J18 0850  6    **f. When **f for each i, we shall have **f, because
J18 0860  3    the operator **f will then be 0 on the range of **f.
J18 0870  1    #DEFINITION.#
J18 0870  2    Let N be a linear operator on the vector space V.
J18 0890  3    We say that N is nilpotent if there is some positive
J18 0900  4    integer r such that **f.
J18 0900  9    #THEOREM 13.#
J18 0900 11    Let T be a linear operator on the finite-dimensional
J18 0910 10    vector space V over the field F. Suppose that the
J18 0920 10    minimal polynomial for T decomposes over F into a
J18 0930  8    product of linear polynomials. Then there is a diagonalizable
J18 0940  7    operator D on V and a nilpotent operator N on V
J18 0950  9    such that (a) **f, (b) **f. The diagonalizable operator
J18 0960  8    D and the nilpotent operator N are uniquely determined
J18 0970  6    by (a) and (b) and each of them is a polynomial in
J18 0980  8    T.
J18 0980  9    _PROOF._
J18 0980 10       We have just observed that we can write **f where
J18 0990  7    D is diagonalizable and N is nilpotent, and where
J18 1000  5    D and N not only commute but are polynomials in T.
J18 1010  6    Now suppose that we also have **f where D' is diagonalizable,
J18 1020  5    N' is nilpotent, and **f. We shall prove that **f.
J18 1030  7       Since D' and N' commute with one another and **f,
J18 1040  7    we see that D' and N' commute with T. Thus D' and
J18 1050  7    N' commute with any polynomial in T; hence they commute
J18 1060 10    with D and with N. Now we have **f or **f and all
J18 1070 12    four of these operators commute with one another. Since
J18 1080  7    D and D' are both diagonalizable and they commute,
J18 1090  7    they are simultaneously diagonalizable, and **f is
J18 1100  5    diagonalizable. Since N and N' are both nilpotent
J18 1110  4    and they commute, the operator **f is nilpotent; for,
J18 1120  2    using the fact that N and N' commute **f and so when
J18 1130  4    r is sufficiently large every term in this expression
J18 1140  1    for **f will be 0. (Actually, a nilpotent operator
J18 1140 10    on an n-dimensional space must have its nth power
J18 1150  7    0; if we take **f above, that will be large enough.
J18 1160  7    It then follows that **f is large enough, but this
J18 1170  4    is not obvious from the above expression.) Now **f
J18 1170 13    is a diagonalizable operator which is also nilpotent.
J18 1180  8    Such an operator is obviously the zero operator; for
J18 1190  7    since it is nilpotent, the minimal polynomial for this
J18 1200  4    operator is of the form **f for some **f; but then
J18 1210  2    since the operator is diagonalizable, the minimal polynomial
J18 1210 10    cannot have a repeated root; hence **f and the minimal
J18 1220 10    polynomial is simply x, which says the operator is
J18 1230  7    0. Thus we see that **f and **f.
J18 1240  2    #COROLLARY.#
J18 1240  3    Let V be a finite-dimensional vector space over an
J18 1250  4    algebraically closed field F, e.g., the field of complex
J18 1260  3    numbers. Then every linear operator T on V can be
J18 1270  3    written as the sum of a diagonalizable operator D
J18 1270 12    and a nilpotent operator N which commute. These operators
J18 1280  9    D and N are unique and each is a polynomial in T.
J18 1290 12       From these results, one sees that the study of linear
J18 1300 11    operators on vector spaces over an algebraically closed
J18 1310  8    field is essentially reduced to the study of nilpotent
J18 1320  6    operators. For vector spaces over non-algebraically
J18 1330  1    closed fields, we still need to find some substitute
J18 1330 10    for characteristic values and vectors. It is a very
J18 1340  9    interesting fact that these two problems can be handled
J18 1350  7    simultaneously and this is what we shall do in the
J18 1360  5    next chapter.
J18 1360  7       In concluding this section, we should like to give
J18 1370  5    an example which illustrates some of the ideas of the
J18 1380  2    primary decomposition theorem. We have chosen to give
J18 1380 10    it at the end of the section since it deals with differential
J18 1390 10    equations and thus is not purely linear algebra.
J18 1400  6    #EXAMPLE 11.#
J18 1400  8    In the primary decomposition theorem, it is not necessary
J18 1410  6    that the vector space V be finite dimensional, nor
J18 1420  5    is it necessary for parts (a) and (b) that p be the
J18 1430  1    minimal polynomial for T. If T is a linear operator
J18 1440  1    on an arbitrary vector space and if there is a monic
J18 1440 12    polynomial p such that **f, then parts (a) and (b)
J18 1450 10    of Theorem 12 are valid for T with the proof which
J18 1460  7    we gave.
J18 1460  9       Let n be a positive integer and let V be the space
J18 1470 10    of all n times continuously differentiable functions
J18 1480  4    f on the real line which satisfy the differential
J18 1490  4    equation **f where **f are some fixed constants. If
J18 1500  2    **f denotes the space of n times continuously differentiable
J18 1510  1    functions, then the space V of solutions of this differential
J18 1520  1    equation is a subspace of **f. If D denotes the differentiation
J18 1530  1    operator and p is the polynomial **f then V is the
J18 1540  3    null space of the operator p(D), because **f simply
J18 1540 12    says **f. Let us now regard D as a linear operator
J18 1550 11    on the subspace V. Then **f.
J18 1560  4       If we are discussing differentiable complex-valued
J18 1570  1    functions, then **f and V are complex vector spaces,
J18 1580  1    and **f may be any complex numbers. We now write **f
J18 1580 12    where **f are distinct complex numbers. If **f is the
J18 1590  8    null space of **f, then Theorem 12 says that **f. In
J18 1600  6    other words, if f satisfies the differential equation
J18 1610  2    **f, then f is uniquely expressible in the form **f
J18 1620  3    where **f satisfies the differential equation **f.
J18 1620 10    Thus, the study of the solutions to the equation **f
J18 1630  9    is reduced to the study of the space of solutions of
J18 1640  6    a differential equation of the form **f. This reduction
J18 1650  2    has been accomplished by the general methods of linear
J18 1650 11    algebra, i.e., by the primary decomposition theorem.
J18 1660  6       To describe the space of solutions to **f, one must
J18 1670  9    know something about differential equations, that is,
J18 1680  4    one must know something about D other than the fact
J18 1690  4    that it is a linear operator. However, one does not
J18 1700  1    need to know very much. It is very easy to establish
J18 1700 12    by induction on r that if f is in **f then **f that
J18 1710 11    is, **f, etc. Thus **f if and only if **f. A function
J18 1720  9    g such that **f, i.e., **f, must be a polynomial function
J18 1730  7    of degree **f or less: **f. Thus f satisfies **f if
J18 1740  6    and only if f has the form **f. Accordingly, the 'functions'
J18 1750  4    **f span the space of solutions of **f. Since **f are
J18 1760  5    linearly independent functions and the exponential
J18 1770  1    function has no zeros, these r functions **f, form
J18 1770 10    a basis for the space of solutions.
